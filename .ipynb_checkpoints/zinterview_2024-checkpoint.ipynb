{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leet code problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum Number of Events That Can Be Attended II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events = [[1,2],[2,3],[3,4]]\n",
    "\n",
    "import heapq\n",
    "\n",
    "class Solution:\n",
    "    def maxEvents(self, events):\n",
    "        n = len(events)\n",
    "        \n",
    "        events.sort()\n",
    "        \n",
    "        start, end = float(\"inf\"), float(\"-inf\")\n",
    "        \n",
    "        for i,j in events:\n",
    "            start = min(start,i)\n",
    "            end = max(end,j)\n",
    "\n",
    "        c, i, h = 0, 0, []\n",
    "\n",
    "        for day in range(start,end+1):\n",
    "            while i < n and events[i][0] == day:\n",
    "                heapq.heappush(h,events[i][1])\n",
    "                i += 1\n",
    "\n",
    "            while h and h[0] < day:\n",
    "                heapq.heappop(h)\n",
    "\n",
    "            if h:\n",
    "                heapq.heappop(h)\n",
    "                c += 1\n",
    "\n",
    "        return c\n",
    "    \n",
    "s = Solution()\n",
    "s.maxEvents(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 442.Find All Duplicates in an Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def duplicates(arr):\n",
    "    freq_map = {}\n",
    "    result = []\n",
    "    for num in arr:\n",
    "        freq_map[num] = freq_map.get(num, 0) + 1\n",
    "\n",
    "    for key, value in freq_map.items():\n",
    "        if value > 1:\n",
    "            result.append(key)\n",
    "    return result\n",
    "\n",
    "duplicates([4,3,2,7,8,2,3,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. two sum Given an array of integers nums and an integer target, return indices of the two numbers such that they add up to target. nums = [2,7,11,15], target = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def twoSum(nums, target):\n",
    "        pair_idx = {}\n",
    "        for i, num in enumerate(nums):\n",
    "            pair_idx[num] = i\n",
    "            #print(pair_idx)\n",
    "            if target - num in pair_idx:\n",
    "                # We check if the difference target - num exists as a key in the pair_idx dictionary.\n",
    "                # If it exists, it means that we have found a pair of numbers whose sum equals the target.\n",
    "                return [i, pair_idx[target - num]]\n",
    "            \n",
    "\n",
    "twoSum([2,7,11,15], 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15. 3 Sum Input: nums = [-1,0,1,2,-1,-4] Output: [[-1,-1,2],[-1,0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1, -1, 2], [-1, 0, 1]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Solution:\n",
    "    def threeSum(self, nums): \n",
    "        nums.sort() # sorting cause we need to avoid duplicates, with this duplicates will be near to each other\n",
    "        l=[]\n",
    "        for i in range(len(nums)):  #this loop will help to fix the one number i.e, i\n",
    "            if i>0 and nums[i-1]==nums[i]:  #skipping if we found the duplicate of i\n",
    "                continue \n",
    "\t\t\t\n",
    "\t\t\t#NOW FOLLOWING THE RULE OF TWO POINTERS AFTER FIXING THE ONE VALUE (i)\n",
    "            j=i+1 #taking j pointer larger than i (as said in ques)\n",
    "            k=len(nums)-1 #taking k pointer from last \n",
    "            while j<k: \n",
    "                s=nums[i]+nums[j]+nums[k] \n",
    "                if s>0: #if sum s is greater than 0(target) means the larger value(from right as nums is sorted i.e, k at right) \n",
    "\t\t\t\t#is taken and it is not able to sum up to the target\n",
    "                    k-=1  #so take value less than previous\n",
    "                elif s<0: #if sum s is less than 0(target) means the shorter value(from left as nums is sorted i.e, j at left) \n",
    "\t\t\t\t#is taken and it is not able to sum up to the target\n",
    "                    j+=1  #so take value greater than previous\n",
    "                else:\n",
    "                    l.append([nums[i],nums[j],nums[k]]) #if sum s found equal to the target (0)\n",
    "                    j+=1 \n",
    "                    while nums[j-1]==nums[j] and j<k: #skipping if we found the duplicate of j and we dont need to check \n",
    "\t\t\t\t\t#the duplicate of k cause it will automatically skip the duplicate by the adjustment of i and j\n",
    "                        j+=1   \n",
    "        return l\n",
    "\n",
    "s = Solution()\n",
    "s.threeSum([-1,0,1,2,-1,-4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 238.Product of Array except itself Input: nums = [1,2,3,4] Output: [24,12,8,6]\n",
    "- https://www.geeksforgeeks.org/a-product-array-puzzle/\n",
    "- https://www.youtube.com/watch?v=bNvIQI2wAjk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The product array is: n\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 2, 6]\n",
      "[24, 12, 8, 6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[24, 12, 8, 6]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def productArray(arr, n): \n",
    "    lst = []\n",
    "    # Base case \n",
    "    if n == 1: \n",
    "        print(0) \n",
    "        return\n",
    "  \n",
    "    i, temp = 1, 1\n",
    "  \n",
    "    # Allocate memory for the product array \n",
    "    prod = [1 for i in range(n)] \n",
    "    print(prod)\n",
    "    # Initialize the product array as 1 \n",
    "  \n",
    "    # In this loop, temp variable contains product of \n",
    "    # elements on left side excluding arr[i] \n",
    "    for i in range(n): \n",
    "        prod[i] = temp \n",
    "        temp *= arr[i] \n",
    "    print(prod)\n",
    "    # Initialize temp to 1 for product on right side \n",
    "    temp = 1\n",
    "  \n",
    "    # In this loop, temp variable contains product of \n",
    "    # elements on right side excluding arr[i] \n",
    "    for i in range(n - 1, -1, -1): \n",
    "        prod[i] *= temp \n",
    "        temp *= arr[i] \n",
    "    print(prod)\n",
    "    # Print the constructed prod array \n",
    "    for i in range(n): \n",
    "        lst.append(prod[i])\n",
    "    return lst\n",
    "  \n",
    "  \n",
    "# Driver Code \n",
    "arr = [1,2,3,4] \n",
    "n = len(arr) \n",
    "print(\"The product array is: n\") \n",
    "productArray(arr, n) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 74.Search in a row wise and column wise sorted matrix\n",
    "- https://www.youtube.com/watch?v=Ber2pi2C0j0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element found at ( 0 , 1 )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def search(mat, n, x):\n",
    "    if(n == 0):\n",
    "        return -1\n",
    " \n",
    "    # Traverse through the matrix\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    " \n",
    "            # If the element is found\n",
    "            if(mat[i][j] == x):\n",
    "                print(\"Element found at (\", i, \",\", j, \")\")\n",
    "                return 1\n",
    " \n",
    "    print(\" Element not found\")\n",
    "    return 0\n",
    "\n",
    "matrix = [[1,3,5,7],[10,11,16,20],[23,30,34,60]]\n",
    "#target = 3\n",
    "search(matrix,n=4, x=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 121. Best Time to Buy and Sell Stock II\n",
    "- https://www.youtube.com/watch?v=1pkOgXD63yU&list=PLot-Xpze53leOBgcVsJBEGrHPd_7x_koV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def maxProfit(prices, n):\n",
    "    buy = prices[0]\n",
    "    max_profit = 0\n",
    "    for i in range(1, n):\n",
    " \n",
    "        # Checking for lower buy value\n",
    "        if (buy > prices[i]):\n",
    "            buy = prices[i]\n",
    " \n",
    "        # Checking for higher profit\n",
    "        elif (prices[i] - buy > max_profit):\n",
    "            max_profit = prices[i] - buy\n",
    "    return max_profit\n",
    "\n",
    "prices = [7, 1, 5, 6, 4]\n",
    "n = len(prices)\n",
    "maxProfit(prices, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  438. Group Anagrams\n",
    "- https://www.youtube.com/watch?v=G8xtZy0fDKg&list=PLot-Xpze53leOBgcVsJBEGrHPd_7x_koV&index=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['cat', 'tac', 'act'], ['dog', 'god']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "def solve(words):\n",
    "    # defaultdict will create a new list if the key is not found in the dictionary\n",
    "    m = defaultdict(list)\n",
    " \n",
    "    # loop over all the words\n",
    "    for word in words:\n",
    "        # Counter('cat') :\n",
    "        #    counts the frequency of the characters present in a string\n",
    "        #    >>> Counter({'c': 1, 'a': 1, 't': 1})\n",
    " \n",
    "        # frozenset(dict(Counter('cat')).items()) :\n",
    "        #    frozenset takes an iterable object as input and makes them immutable.\n",
    "        #    So that hash(frozenset(Counter('cat'))) is equal to\n",
    "        #   hash of other 'cat' anagrams \n",
    "        #    >>> frozenset({('c', 1), ('a', 1), ('t', 1)})\n",
    "        m[frozenset(dict(Counter(word)).items())].append(word)\n",
    "    return [v for k, v in m.items()]\n",
    " \n",
    "solve([\"cat\", \"dog\", \"tac\", \"god\", \"act\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 33.Search in Rotated Sorted Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def search_rotated_array(arr, key):\n",
    "    n = len(arr)\n",
    "    for i in range(n):\n",
    "        if arr[i] == key:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "search_rotated_array([4,5,6,7,0,1,2], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 32. Longest Valid Parentheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def findMaxLen(string):\n",
    "    n = len(string)\n",
    "\n",
    "    # Create a stack and push -1\n",
    "    # as initial index to it.\n",
    "    stk = []\n",
    "    stk.append(-1)\n",
    "\n",
    "    # Initialize result\n",
    "    result = 0\n",
    "\n",
    "    # Traverse all characters of given string\n",
    "    for i in range(n):\n",
    "\n",
    "        # If opening bracket, push index of it\n",
    "        if string[i] == '(':\n",
    "            stk.append(i)\n",
    "        \n",
    "        # If closing bracket, i.e., str[i] = ')'\n",
    "        else:\n",
    "\n",
    "            # Pop the previous opening bracket's index\n",
    "            if len(stk) != 0:\n",
    "                stk.pop()\n",
    "\n",
    "            # Check if this length formed with base of\n",
    "            # current valid substring is more than max\n",
    "            # so far\n",
    "            if len(stk) != 0:\n",
    "                result = max(result,\n",
    "                            i - stk[len(stk)-1])\n",
    "\n",
    "            # If stack is empty. push current index as\n",
    "            # base for next valid substring (if any)\n",
    "            else:\n",
    "                stk.append(i)\n",
    "\n",
    "    return result\n",
    "\n",
    "findMaxLen(\")()())\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1456. Maximum Number of Vowels in a Substring of Given Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def maxVowels(s: str, k: int):\n",
    "    vowels = frozenset(\"aeiou\")\n",
    "    cnt = ans = sum(s[i] in vowels for i in range(k))\n",
    "    for i in range(k, len(s)):\n",
    "        cnt += (s[i] in vowels) - (s[i - k] in vowels)\n",
    "        ans = max(cnt, ans)\n",
    "    return ans\n",
    "\n",
    "maxVowels(\"abciiidef\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def longestVowel(s): \n",
    "    count, res = 0, 0\n",
    "    vowels = ['a','e','i','o','u']\n",
    "    for i in range(len(s)): \n",
    "        if s[i] in vowels: \n",
    "                count += 1\n",
    "        else: \n",
    "            # check previous value \n",
    "            # is greater then or not \n",
    "            res = max(res, count) \n",
    "            count = 0\n",
    "    return max(res, count) \n",
    "\n",
    "longestVowel(\"theeare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 200. Number of Islands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numIslands(grid):\n",
    "\n",
    "    # length of row and column\n",
    "    global row , col\n",
    "    row , col = len(grid) , len(grid[0])\n",
    "\n",
    "    # Getting value from grid\n",
    "    def getValue(i,j,grid):\n",
    "        global row , col\n",
    "        if -1 < i < row and -1 < j < col:\n",
    "            return grid[i][j]\n",
    "        return '0'\n",
    "\n",
    "    # remove connecting land \n",
    "    def connecting(i,j,grid):\n",
    "        grid[i][j] = '0'\n",
    "\n",
    "        if getValue(i-1,j,grid) == '1':\n",
    "            connecting(i-1,j,grid)\n",
    "        if getValue(i+1,j,grid) == '1':\n",
    "            connecting(i+1,j,grid)\n",
    "        if getValue(i,j-1,grid) == '1':\n",
    "            connecting(i,j-1,grid)\n",
    "        if getValue(i,j+1,grid) == '1':\n",
    "            connecting(i,j+1,grid)\n",
    "\n",
    "    # iterate over grid\n",
    "    count = 0\n",
    "    for i in range(row):\n",
    "        for j in range(col):\n",
    "            if grid[i][j] == '1':\n",
    "                connecting(i,j,grid)\n",
    "                count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numIslands([[\"1\",\"1\",\"0\",\"0\",\"0\"],[\"1\",\"1\",\"0\",\"0\",\"0\"],[\"0\",\"0\",\"1\",\"0\",\"0\"],[\"0\",\"0\",\"0\",\"1\",\"1\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### flattening of dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_dictionary {'geeks': {'Geeks': {'for': 7}}, 'for': {'geeks': {'Geeks': 3}}, 'Geeks': {'for': {'for': 1, 'geeks': 4}}}\n",
      "final_dictionary {'geeks_Geeks_for': 7, 'for_geeks_Geeks': 3, 'Geeks_for_for': 1, 'Geeks_for_geeks': 4}\n"
     ]
    }
   ],
   "source": [
    "def flatten_dict(dd, separator ='_', prefix =''):\n",
    "\treturn { prefix + separator + k if prefix else k : v\n",
    "\t\t\tfor kk, vv in dd.items()\n",
    "\t\t\tfor k, v in flatten_dict(vv, separator, kk).items()\n",
    "\t\t\t} if isinstance(dd, dict) else { prefix : dd }\n",
    "\t\t\n",
    "# initialising_dictionary\n",
    "ini_dict = {'geeks': {'Geeks': {'for': 7}},\n",
    "\t\t\t'for': {'geeks': {'Geeks': 3}},\n",
    "\t\t\t'Geeks': {'for': {'for': 1, 'geeks': 4}}}\n",
    "\n",
    "# printing initial dictionary\n",
    "print (\"initial_dictionary\", str(ini_dict))\n",
    "\n",
    "# printing final dictionary\n",
    "print (\"final_dictionary\", str(flatten_dict(ini_dict)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'geeks_Geeks_for': 7,\n",
       " 'for_geeks_Geeks': 3,\n",
       " 'Geeks_for_for': 1,\n",
       " 'Geeks_for_geeks': 4}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ini_dict = {'geeks': {'Geeks': {'for': 7}},\n",
    "            'for': {'geeks': {'Geeks': 3}},\n",
    "            'Geeks': {'for': {'for': 1, 'geeks': 4}}}\n",
    "df = pd.json_normalize(ini_dict, sep='_')\n",
    "df.iloc[0].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1045. Customers Who Bought All Products\n",
    "- https://www.youtube.com/watch?v=JyGknIby4Ko\n",
    "- select customer_id from customer\n",
    "group by customer_id having count(distinct product_key)=(select count(product_key) from product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 197. Rising Temperature\n",
    "- https://www.youtube.com/watch?v=CTg-81wvl2U\n",
    "- select a.id from weather a inner join weather b on datediff(dd, a.recordDate, b.recordDate) = 1\n",
    "and a.temperature > b.temperature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Highest Salary\n",
    "- select * from employee where salary = (select max(salary) from employee where salary < (select max(salary) from employee))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1070. Product Sales Analysis III\n",
    "- https://www.youtube.com/watch?v=L2dvdq-M-Rs\n",
    "- select product_id, year as first_year, quantity, price from (\n",
    "\tselect product_id, year, quantity, price, DENSE_RANK() over(partition by product_id order by year asc) as dns\n",
    "\tfrom sales \n",
    "\t)as k  where dns =1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 262. Trips and Users\n",
    "- https://www.youtube.com/watch?v=U15X79REEX8\n",
    "- select request as day, round(sum(case when status in ('cancel') then 1 else 0 end)/count(1),2) as cancellation_rate from trips \n",
    "where request between '2013-10-01' and '2013-10-03'\n",
    "and client_id not in (select USER_ID from users where banned='yes')\n",
    "and driver_id not in (select USER_ID from users where banned='yes')\n",
    "group by 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2356. Number of Unique Subjects Taught by Each Teacher\n",
    "- select teacher_id, count(distinct subject_id) as cnt from teacher group by teacher_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 5 product from sales amount\n",
    "- Select product , sum ( sales amount ) from table name group by product order total sakes desc limit 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>St_id</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   St_id  age\n",
       "0      1   15\n",
       "1      2   11\n",
       "2      3   11\n",
       "3      4   20"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "st_data = [[1, 15],[2, 11],[3, 11],[4, 20]]\n",
    "pd.DataFrame(st_data, columns=['St_id','age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>st_id</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>hey</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   st_id name  age\n",
       "0    101  hey   13"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'st_id':[101,53,128,3],'name':['hey','hi','hell','me'],'age':[13,10,6,11]})\n",
    "df[df['st_id']==101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hey</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hi</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hell</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>me</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name  age\n",
       "0   hey   26\n",
       "1    hi   20\n",
       "2  hell   12\n",
       "3    me   22"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'name':['hey','hi','hell','me'],'age':[13,10,6,11]})\n",
    "df['age'] = df['age']*2\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'st_id':[101,53,128,3],'name':['hey','hi','hell','me'],'age':[13,10,6,11]})\n",
    "#df.melt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'animals' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-94626da601eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0manimals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manimals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0manimals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"weight\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0manimals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manimals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"weight\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manimals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"name\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'animals' is not defined"
     ]
    }
   ],
   "source": [
    "animals = animals[animals[\"weight\"]>100]\n",
    "animals = animals.sort_values(by=\"weight\",ascending=False)\n",
    "f = pd.DataFrame(animals[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Python code to read a 5GB CSV file without memory errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the CSV file\n",
    "file_path = 'large_file.csv'\n",
    "\n",
    "# Define chunk size (number of rows per chunk)\n",
    "chunk_size = 100000  # You can adjust this based on your system memory\n",
    "\n",
    "# Iterate through the file in chunks\n",
    "for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
    "    # Process each chunk here\n",
    "    # For example, just print the shape of each chunk\n",
    "    print(f\"Processing chunk with shape: {chunk.shape}\")\n",
    "\n",
    "    # You can also apply transformations, filtering, aggregation etc. here.\n",
    "    # For example:\n",
    "    # chunk_filtered = chunk[chunk['column_name'] > 1000]\n",
    "    # chunk_filtered.to_csv('processed_output.csv', mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk a large dataframe into batches of 5000 rows and insert into SQL DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Sample large dataframe for demonstration (replace with your actual data)\n",
    "df = pd.DataFrame({\n",
    "    'id': range(1, 100001),\n",
    "    'name': ['Name_' + str(i) for i in range(1, 100001)]\n",
    "})\n",
    "\n",
    "# Database connection string (modify according to your DB)\n",
    "# Example for MySQL:\n",
    "# mysql+pymysql://username:password@host:port/dbname\n",
    "\n",
    "connection_string = \"mysql+pymysql://user:password@localhost:3306/my_database\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Define chunk size\n",
    "chunk_size = 5000\n",
    "\n",
    "# Insert in chunks\n",
    "for start in range(0, len(df), chunk_size):\n",
    "    end = start + chunk_size\n",
    "    chunk = df.iloc[start:end]\n",
    "\n",
    "    # Insert chunk into DB\n",
    "    chunk.to_sql(\n",
    "        name='target_table',\n",
    "        con=engine,\n",
    "        if_exists='append',   # Append to existing table\n",
    "        index=False           # Don't write dataframe index to DB\n",
    "    )\n",
    "\n",
    "    print(f\"Inserted rows {start} to {end-1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle missing values logically in a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>M</td>\n",
       "      <td>50000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>80000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>M</td>\n",
       "      <td>90000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID   Age Gender   Salary\n",
       "0   1  25.0      M  50000.0\n",
       "1   2   NaN      F  60000.0\n",
       "2   3  35.0    NaN      NaN\n",
       "3   4   NaN      F  80000.0\n",
       "4   5  45.0      M  90000.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample dataframe with missing values\n",
    "data = {\n",
    "    'ID': [1, 2, 3, 4, 5],\n",
    "    'Age': [25, np.nan, 35, np.nan, 45],\n",
    "    'Gender': ['M', 'F', np.nan, 'F', 'M'],\n",
    "    'Salary': [50000, 60000, np.nan, 80000, 90000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>M</td>\n",
       "      <td>50000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>F</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>35.0</td>\n",
       "      <td>F</td>\n",
       "      <td>80000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>M</td>\n",
       "      <td>90000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID   Age Gender   Salary\n",
       "0   1  25.0      M  50000.0\n",
       "1   2  35.0      F  60000.0\n",
       "2   3  35.0    NaN  70000.0\n",
       "3   4  35.0      F  80000.0\n",
       "4   5  45.0      M  90000.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill with mean/median\n",
    "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "df['Salary'] = df['Salary'].fillna(df['Salary'].mean())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>M</td>\n",
       "      <td>50000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>F</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>35.0</td>\n",
       "      <td>F</td>\n",
       "      <td>80000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>M</td>\n",
       "      <td>90000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID   Age Gender   Salary\n",
       "0   1  25.0      M  50000.0\n",
       "1   2  35.0      F  60000.0\n",
       "2   3  35.0    NaN  70000.0\n",
       "3   4  35.0      F  80000.0\n",
       "4   5  45.0      M  90000.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use forward fill / backward fill (good for time-series)\n",
    "\n",
    "df['Age'] = df['Age'].fillna(method='ffill')\n",
    "df['Age'] = df['Age'].fillna(method='bfill')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write logic to compare two datasets and identify mismatches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismatched Records:\n",
      "   ID Name_df1  Salary_df1  Name_df2  Salary_df2  Name_mismatch  \\\n",
      "1   2      Bob       60000       Bob       65000          False   \n",
      "2   3  Charlie       70000  CharlieX       70000           True   \n",
      "3   4    David       80000     David       90000          False   \n",
      "\n",
      "   Salary_mismatch  \n",
      "1             True  \n",
      "2            False  \n",
      "3             True  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data1 = {\n",
    "    'ID': [1, 2, 3, 4],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'Salary': [50000, 60000, 70000, 80000]\n",
    "}\n",
    "\n",
    "data2 = {\n",
    "    'ID': [1, 2, 3, 4],\n",
    "    'Name': ['Alice', 'Bob', 'CharlieX', 'David'],\n",
    "    'Salary': [50000, 65000, 70000, 90000]\n",
    "}\n",
    "\n",
    "df1 = pd.DataFrame(data1)\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "# Merge both datasets on ID for comparison\n",
    "merged = df1.merge(df2, on='ID', how='outer', suffixes=('_df1', '_df2'))\n",
    "\n",
    "# Create mismatch flags for each column\n",
    "for col in ['Name', 'Salary']:\n",
    "    merged[f'{col}_mismatch'] = merged[f'{col}_df1'] != merged[f'{col}_df2']\n",
    "\n",
    "# Filter rows where any mismatch exists\n",
    "mismatches = merged[merged[[f'{col}_mismatch' for col in ['Name', 'Salary']]].any(axis=1)]\n",
    "\n",
    "print(\"Mismatched Records:\")\n",
    "print(mismatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Name   Salary\n",
      "1 self        NaN  60000.0\n",
      "  other       NaN  65000.0\n",
      "2 self    Charlie      NaN\n",
      "  other  CharlieX      NaN\n",
      "3 self        NaN  80000.0\n",
      "  other       NaN  90000.0\n"
     ]
    }
   ],
   "source": [
    "#Bonus (if no primary key present)\n",
    "comparison = df1.compare(df2, align_axis=0)\n",
    "print(comparison)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design a simple ETL pipeline using Python (without using frameworks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'input_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-e13192fb6dd2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mrun_etl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-e13192fb6dd2>\u001b[0m in \u001b[0;36mrun_etl\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;31m# ---------- MAIN ETL ----------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrun_etl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mdf_extracted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCSV_FILE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[0mdf_transformed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_extracted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_transformed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDB_CONNECTION_STRING\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-e13192fb6dd2>\u001b[0m in \u001b[0;36mextract\u001b[1;34m(csv_file)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Extracting data...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    686\u001b[0m     )\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 948\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2010\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'input_data.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "\n",
    "# ---------- CONFIGURATION ----------\n",
    "CSV_FILE = 'input_data.csv'\n",
    "DB_CONNECTION_STRING = 'sqlite:///etl_db.sqlite3'  # You can replace with your DB connection string\n",
    "\n",
    "# ---------- EXTRACT ----------\n",
    "def extract(csv_file):\n",
    "    print(\"Extracting data...\")\n",
    "    df = pd.read_csv(csv_file)\n",
    "    return df\n",
    "\n",
    "# ---------- TRANSFORM ----------\n",
    "def transform(df):\n",
    "    print(\"Transforming data...\")\n",
    "\n",
    "    # Example transformations:\n",
    "    df['Name'] = df['Name'].str.strip().str.title()  # clean name format\n",
    "    df['Salary'] = df['Salary'].fillna(50000)        # fill missing salaries\n",
    "    df['JoinDate'] = pd.to_datetime(df['JoinDate'], errors='coerce')  # convert date\n",
    "    df = df.dropna(subset=['JoinDate'])              # drop rows with invalid dates\n",
    "\n",
    "    return df\n",
    "\n",
    "# ---------- LOAD ----------\n",
    "def load(df, db_connection_string, table_name='employees'):\n",
    "    print(\"Loading data into database...\")\n",
    "    engine = create_engine(db_connection_string)\n",
    "    df.to_sql(table_name, con=engine, if_exists='replace', index=False)\n",
    "    print(\"Load completed.\")\n",
    "\n",
    "# ---------- MAIN ETL ----------\n",
    "def run_etl():\n",
    "    df_extracted = extract(CSV_FILE)\n",
    "    df_transformed = transform(df_extracted)\n",
    "    load(df_transformed, DB_CONNECTION_STRING)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_etl()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
